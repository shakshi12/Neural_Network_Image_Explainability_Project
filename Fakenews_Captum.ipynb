{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shakshi12/Neural_Network_Image_Explainability_Project/blob/main/Fakenews_Captum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwvGFz1AT-Jj"
      },
      "source": [
        "# Showcases integrated gradients on Fake news dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLY0Oj9zUQAQ"
      },
      "outputs": [],
      "source": [
        "!pip install captum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyNjSZ3gT-Ju"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import Saliency\n",
        "from captum.attr import DeepLift\n",
        "from captum.attr import NoiseTunnel\n",
        "from captum.attr import visualization as viz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3kQUybJE-Dd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "from skimage import io#, transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3aj5844IHmz"
      },
      "outputs": [],
      "source": [
        "#fake_news_txt = pd.read_csv('/content/misinfo_anonymized.txt', sep = '\\t')\n",
        "#true_news_txt = pd.read_csv('/content/notmisinfo_anonymized.txt', sep = '\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BhrxZIgI2bA"
      },
      "outputs": [],
      "source": [
        "\n",
        "n = 65\n",
        "img_name = fake_news_txt.loc[n, 'cluster_image_name']\n",
        "\n",
        "print('Image name: {}'.format(img_name))\n",
        "print('Fake News')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhXxCuW-IkmS"
      },
      "outputs": [],
      "source": [
        "fake_news_txt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTLTnmpfJwUD"
      },
      "outputs": [],
      "source": [
        "fake_news_txt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBG0ONdiEFhB"
      },
      "outputs": [],
      "source": [
        "\n",
        "n = 65\n",
        "img_name = true_news_txt.loc[n, 'cluster_image_name']\n",
        "#landmarks = landmarks_frame.iloc[n, 1:]\n",
        "#landmarks = np.asarray(landmarks)\n",
        "#landmarks = landmarks.astype('float').reshape(-1, 2)\n",
        "\n",
        "print('Image name: {}'.format(img_name))\n",
        "print('True News')\n",
        "true_news_txt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loGctjpCHO4-"
      },
      "outputs": [],
      "source": [
        "def show_news(image, landmarks):\n",
        "    \"\"\"Show image with fake news\"\"\"\n",
        "    plt.imshow(image)\n",
        "    plt.title(landmarks)\n",
        "    #plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "#img_name = 'Ag-1I3smJYfxkog_OtgFmXdw6hNFGnXryPEjZfp2VaSZ.jpeg'\n",
        "#news(io.imread(os.path.join('/content/misinfo/', img_name)),\n",
        "     #          'fake news')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbRPdeMKGhY5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def load_images_from_folder(folder):\n",
        "    fake_images = np.zeros((771, 3072))\n",
        "    print(fake_images.shape)\n",
        "    for filename in os.listdir(folder):\n",
        "       # img = Image.open(r'C:\\Users\\shakshi\\Documents\\Courses\\Neural Networks\\Project\\icwsm_dataset_share\\india\\misinfo\\Ag_03_zCikWIdryKPjSCGsBEQ-s1abSF-bhyxpkJdZba.jpeg')#.convert('L')\n",
        "         img = Image.open(os.path.join(folder,filename))\n",
        "\n",
        "        # asarray() class is used to convert\n",
        "        # PIL images into NumPy arrays\n",
        "         numpydata = asarray(img)\n",
        "         numpydata.resize((32,32,3))\n",
        "         np.append(fake_images, numpydata.flatten().reshape([1, 3072]), axis = 0)\n",
        "    return fake_images\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGr2TCfvN5JY"
      },
      "outputs": [],
      "source": [
        "#os.rename(r'C:\\Users\\Ron\\Desktop\\Test\\Products.txt',r'C:\\Users\\Ron\\Desktop\\Test\\Shipped Products.txt')\n",
        "import os\n",
        "def filename_renaming(folder):\n",
        "    #fake_images = np.zeros((771, 3072))\n",
        "    for filename in os.listdir(folder):\n",
        "       # img = Image.open(r'C:\\Users\\shakshi\\Documents\\Courses\\Neural Networks\\Project\\icwsm_dataset_share\\india\\misinfo\\Ag_03_zCikWIdryKPjSCGsBEQ-s1abSF-bhyxpkJdZba.jpeg')#.convert('L')\n",
        "        # img = Image.open(os.path.join(folder,filename))\n",
        "         #os.rename(os.path.join(folder,filename),os.path.join(folder,filename+'fake'))\n",
        "         file = filename.split(\".\")\n",
        "         os.rename(os.path.join(folder,filename), os.path.join(folder, file[0]+\"_real\" + \".\" +file[1]))\n",
        "        # asarray() class is used to convert\n",
        "        # PIL images into NumPy arrays\n",
        "        # numpydata = asarray(img)\n",
        "         #numpydata.resize((32,32,3))\n",
        "         #np.append(fake_images, numpydata.flatten().reshape([1, 3072]), axis = 0)\n",
        "   # return fake_images\n",
        "\n",
        "folder = r'/content/not_misinfo/'\n",
        "filename_renaming(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYJ-iyMEQNB0"
      },
      "outputs": [],
      "source": [
        "filename = 'Ag-1I3smJYfxkog_OtgFmXdw6hNFGnXryPEjZfp2VaSZ.jpeg'\n",
        "print(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB2Q34e2P__k"
      },
      "outputs": [],
      "source": [
        "'Ag18N9PS3s9rOA1Cv9Fz1Mbxw3XDZaUjh3rMK8wkx685_real.jpeg'.split(\"_\")[1] == 'real.jpeg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwF66OR1R0M7"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "from glob import glob\n",
        "\n",
        "folder = r'/content/not_misinfo/'\n",
        "files = glob(r\"/content/not_misinfo/*.jpeg\")\n",
        "shuffle(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLLEfC_1E3PD"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class FakeNewsDataset(Dataset):\n",
        "    \"\"\"Fake news dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        #self.landmarks_frame = pd.read_csv(csv_file, sep = '\\t')\n",
        "        self.labels = pd.DataFrame(np.ones((1551))) # fake and true labels\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        print(idx)\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "       # img_name = os.path.join(self.root_dir,\n",
        "            #                    self.landmarks_frame.loc[idx, 'cluster_image_name'])\n",
        "        folder = r'/content/not_misinfo/'\n",
        "        count = -1\n",
        "        for filename in os.listdir(folder):\n",
        "          img_name = np.random.rand(256,256)\n",
        "          count = count + 1\n",
        "          if (idx == count):\n",
        "            #print(filename)\n",
        "            img_name = Image.open(os.path.join(folder,filename))\n",
        "            break\n",
        "        # asarray() class is used to convert\n",
        "        # PIL images into NumPy arrays\n",
        "        numpydata = asarray(img_name)\n",
        "         #numpydata.resize((32,32,3))\n",
        "         #print(numpydata.flatten().reshape(-1).shape)\n",
        "         #np.append(fake_images, numpydata.flatten().reshape([1, 3072]), axis = 0)\n",
        "        #image = io.imread(numpydata)\n",
        "        #landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
        "        #landmarks = np.array([landmarks])\n",
        "        #landmarks = landmarks.astype('float').reshape(-1, 2)\n",
        "        #if (filename.split(\"_\") == True):\n",
        "        try:\n",
        "          if (filename.split(\"_\")[1] == 'real.jpeg'):\n",
        "            #print(filename)\n",
        "            sample = {'image': numpydata, 'landmarks': 'true news'}\n",
        "          else:\n",
        "            sample = {'image': numpydata, 'landmarks': 'fake news'}\n",
        "        except:\n",
        "         # print(filename)\n",
        "          sample = {'image': numpydata, 'landmarks': 'fake news'}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHgJFUuFJABd"
      },
      "outputs": [],
      "source": [
        "#face_dataset = FakeNewsDataset(csv_file='/content/misinfo_anonymized.txt',\n",
        " #                                   root_dir='/content/misinfo')\n",
        "fake_dataset = FakeNewsDataset(csv_file='/content/not_misinfo',\n",
        "                                   root_dir='/content/not_misinfo')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(len(fake_dataset)):\n",
        "    sample = fake_dataset[i]\n",
        "\n",
        "    print(i, sample['image'].shape)\n",
        "\n",
        "    ax = plt.subplot(1, 7, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "    show_news(**sample)\n",
        "    #plt.imshow(**sample)\n",
        "\n",
        "    if i == 6:\n",
        "        plt.show()\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp3eYyVhUJ1t"
      },
      "outputs": [],
      "source": [
        "#face_dataset = FakeNewsDataset(csv_file='/content/misinfo_anonymized.txt',\n",
        " #                                   root_dir='/content/misinfo')\n",
        "fake_dataset = FakeNewsDataset(csv_file='/content/not_misinfo',\n",
        "                                   root_dir='/content/not_misinfo')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "#for i in range(len(fake_dataset)):\n",
        " #   sample = fake_dataset[i]\n",
        "import random\n",
        "r = random.randint(0, len(fake_dataset))\n",
        "sample = fake_dataset[r]\n",
        "print(r, sample['image'].shape)\n",
        "\n",
        "#ax = plt.subplot(1, r, r + 1)\n",
        "plt.tight_layout()\n",
        "ax.set_title('Sample #{}'.format(r))\n",
        "ax.axis('off')\n",
        "show_news(**sample)\n",
        "    #plt.imshow(**sample)\n",
        "\n",
        "    #if i == 6:\n",
        "plt.show()\n",
        "     #   break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#face_dataset = FakeNewsDataset(csv_file='/content/misinfo_anonymized.txt',\n",
        " #                                   root_dir='/content/misinfo')\n",
        "fake_dataset = FakeNewsDataset(csv_file='/content/not_misinfo',\n",
        "                                   root_dir='/content/not_misinfo')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "#for i in range(len(fake_dataset)):\n",
        " #   sample = fake_dataset[i]\n",
        "import random\n",
        "r = random.randint(0, len(fake_dataset))\n",
        "sample = fake_dataset[r]\n",
        "print(r, sample['image'].shape)\n",
        "\n",
        "#ax = plt.subplot(1, r, r + 1)\n",
        "plt.tight_layout()\n",
        "ax.set_title('Sample #{}'.format(r))\n",
        "ax.axis('off')\n",
        "show_news(**sample)\n",
        "    #plt.imshow(**sample)\n",
        "\n",
        "    #if i == 6:\n",
        "plt.show()\n",
        "     #   break"
      ],
      "metadata": {
        "id": "Yyn3QcVI9Inm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rnfb3UF3UqPu"
      },
      "outputs": [],
      "source": [
        "#face_dataset = FakeNewsDataset(csv_file='/content/misinfo_anonymized.txt',\n",
        " #                                   root_dir='/content/misinfo')\n",
        "fake_dataset = FakeNewsDataset(csv_file='/content/not_misinfo',\n",
        "                                   root_dir='/content/not_misinfo')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "#for i in range(len(fake_dataset)):\n",
        " #   sample = fake_dataset[i]\n",
        "import random\n",
        "r = random.randint(0, len(fake_dataset))\n",
        "sample = fake_dataset[r]\n",
        "print(r, sample['image'].shape)\n",
        "\n",
        "#ax = plt.subplot(1, r, r + 1)\n",
        "plt.tight_layout()\n",
        "ax.set_title('Sample #{}'.format(r))\n",
        "ax.axis('off')\n",
        "show_news(**sample)\n",
        "    #plt.imshow(**sample)\n",
        "\n",
        "    #if i == 6:\n",
        "plt.show()\n",
        "     #   break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU7P3OYpX5IM"
      },
      "outputs": [],
      "source": [
        "#face_dataset = FakeNewsDataset(csv_file='/content/misinfo_anonymized.txt',\n",
        " #                                   root_dir='/content/misinfo')\n",
        "fake_dataset = FakeNewsDataset(csv_file='/content/not_misinfo',\n",
        "                                   root_dir='/content/not_misinfo')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "#for i in range(len(fake_dataset)):\n",
        " #   sample = fake_dataset[i]\n",
        "import random\n",
        "r = random.randint(0, len(fake_dataset))\n",
        "sample = fake_dataset[r]\n",
        "print(r, sample['image'].shape)\n",
        "\n",
        "#ax = plt.subplot(1, r, r + 1)\n",
        "plt.tight_layout()\n",
        "ax.set_title('Sample #{}'.format(r))\n",
        "ax.axis('off')\n",
        "show_news(**sample)\n",
        "    #plt.imshow(**sample)\n",
        "\n",
        "    #if i == 6:\n",
        "plt.show()\n",
        "     #   break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLrweM91KQvh"
      },
      "outputs": [],
      "source": [
        "#face_dataset = FakeNewsDataset(csv_file='/content/misinfo_anonymized.txt',\n",
        " #                                   root_dir='/content/misinfo')\n",
        "fake_dataset = FakeNewsDataset(csv_file='/content/not_misinfo',\n",
        "                                   root_dir='/content/not_misinfo')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "#for i in range(len(fake_dataset)):\n",
        " #   sample = fake_dataset[i]\n",
        "import random\n",
        "r = random.randint(0, len(fake_dataset))\n",
        "sample = fake_dataset[r]\n",
        "print(r, sample['image'].shape)\n",
        "\n",
        "#ax = plt.subplot(1, r, r + 1)\n",
        "plt.tight_layout()\n",
        "ax.set_title('Sample #{}'.format(r))\n",
        "ax.axis('off')\n",
        "show_news(**sample)\n",
        "    #plt.imshow(**sample)\n",
        "\n",
        "    #if i == 6:\n",
        "plt.show()\n",
        "     #   break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kerh0IYWZW-O"
      },
      "outputs": [],
      "source": [
        "#face_dataset = FakeNewsDataset(csv_file='/content/misinfo_anonymized.txt',\n",
        " #                                   root_dir='/content/misinfo')\n",
        "fake_dataset = FakeNewsDataset(csv_file='/content/not_misinfo',\n",
        "                                   root_dir='/content/not_misinfo')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "#for i in range(len(fake_dataset)):\n",
        " #   sample = fake_dataset[i]\n",
        "import random\n",
        "r = random.randint(0, len(fake_dataset))\n",
        "sample = fake_dataset[r]\n",
        "print(r, sample['image'].shape)\n",
        "\n",
        "#ax = plt.subplot(1, r, r + 1)\n",
        "plt.tight_layout()\n",
        "ax.set_title('Sample #{}'.format(r))\n",
        "ax.axis('off')\n",
        "show_news(**sample)\n",
        "    #plt.imshow(**sample)\n",
        "\n",
        "    #if i == 6:\n",
        "plt.show()\n",
        "     #   break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpW6oEInJtPk"
      },
      "outputs": [],
      "source": [
        "len(fake_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSzpEULVJAvs"
      },
      "outputs": [],
      "source": [
        "type(fake_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXWSuKhKLptw"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms, utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfV2ra82LyO4"
      },
      "outputs": [],
      "source": [
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        #img = transform.resize(image, (new_h, new_w))\n",
        "        img = image\n",
        "\n",
        "        # h and w are swapped for landmarks because for images,\n",
        "        # x and y axes are axis 1 and 0 respectively\n",
        "        #landmarks = landmarks * [new_w / w, new_h / h]\n",
        "\n",
        "        return {'image': img, 'landmarks': landmarks}\n",
        "\n",
        "\n",
        "class RandomCrop(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, square crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = (output_size, output_size)\n",
        "        else:\n",
        "            assert len(output_size) == 2\n",
        "            self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        new_h, new_w = self.output_size\n",
        "\n",
        "        top = np.random.randint(0, h - new_h)\n",
        "        left = np.random.randint(0, w - new_w)\n",
        "\n",
        "        image = image[top: top + new_h,\n",
        "                      left: left + new_w]\n",
        "\n",
        "        #landmarks = landmarks - [left, top]\n",
        "\n",
        "        return {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C x H x W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return torch.from_numpy(image.astype(np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkJrw28zM-io"
      },
      "outputs": [],
      "source": [
        "scale = Rescale(256)\n",
        "crop = RandomCrop(128)\n",
        "composed = transforms.Compose([Rescale(256),\n",
        "                               RandomCrop(224)])\n",
        "\n",
        "# Apply each of the above transforms on sample.\n",
        "fig = plt.figure()\n",
        "r = random.randint(0, len(fake_dataset))\n",
        "sample = fake_dataset[r]\n",
        "for i, tsfrm in enumerate([scale, crop, composed]):\n",
        "    transformed_sample = tsfrm(sample)\n",
        "\n",
        "    ax = plt.subplot(1, 3, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(type(tsfrm).__name__)\n",
        "    show_news(**transformed_sample)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJCBjSG7ZePp"
      },
      "outputs": [],
      "source": [
        "scale = Rescale(256)\n",
        "crop = RandomCrop(128)\n",
        "composed = transforms.Compose([Rescale(256),\n",
        "                               RandomCrop(224)])\n",
        "\n",
        "# Apply each of the above transforms on sample.\n",
        "fig = plt.figure()\n",
        "r = random.randint(0, len(fake_dataset))\n",
        "sample = fake_dataset[r]\n",
        "for i, tsfrm in enumerate([scale, crop, composed]):\n",
        "    transformed_sample = tsfrm(sample)\n",
        "\n",
        "    ax = plt.subplot(1, 3, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(type(tsfrm).__name__)\n",
        "    show_news(**transformed_sample)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI0Qu0rJJAx3"
      },
      "outputs": [],
      "source": [
        "transformed_dataset = FakeNewsDataset(csv_file='/content/misinfo',\n",
        "                                    root_dir='/content/misinfo',\n",
        "                                           transform=transforms.Compose([\n",
        "                                               Rescale(256),\n",
        "                                               RandomCrop(32),\n",
        "                                               ToTensor()\n",
        "                                           ]))\n",
        "\n",
        "for i in range(len(transformed_dataset)):\n",
        "    sample = transformed_dataset[i]\n",
        "\n",
        "    print(i, sample.shape)\n",
        "\n",
        "    if i == 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jBorvPwJA5P"
      },
      "outputs": [],
      "source": [
        "#transform = transforms.Compose(\n",
        "    [#transforms.ToTensor(),\n",
        " #    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#transformed_dataset = FakeNewsDataset(csv_file='/content/misinfo_anonymized.txt',\n",
        " #                                   root_dir='/content/misinfo',\n",
        "  #                                         transform=transform\n",
        "   #                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igRZiv4HK-5o"
      },
      "outputs": [],
      "source": [
        "#transform = transforms.Compose(\n",
        " #   [transforms.ToTensor(),\n",
        "  #   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#trainset = transformed_dataset(transform=transform)\n",
        "#trainset = transformed_dataset(transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(transformed_dataset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "#testset = transformed_dataset(transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(transformed_dataset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('fake news', 'true news')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader"
      ],
      "metadata": {
        "id": "XVA2DY3f9iG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmWEuCrZT-J1"
      },
      "source": [
        "We define a classification network based on the architecture proposed in the following tutorial:\n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJiNtDkyT-J2"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "       # x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.relu4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnp8xHbTT-J4"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qbvZMxFT-J6"
      },
      "outputs": [],
      "source": [
        "USE_PRETRAINED_MODEL = False\n",
        "# USE_PRETRAINED_MODEL = False\n",
        "\n",
        "if USE_PRETRAINED_MODEL:\n",
        "    print(\"Using existing trained model\")\n",
        "    net.load_state_dict(torch.load('cifar_torchvision.pt'))\n",
        "else:\n",
        "    for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs = data\n",
        "            if (i < 771):\n",
        "              labels = torch.zeros(4, dtype = int)\n",
        "            else:\n",
        "              labels = torch.ones(4, dtype = int)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 2000))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "    torch.save(net.state_dict(), 'models/cifar_torchvision.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDAKq5ltT-J7"
      },
      "source": [
        "In the cell below we load some images from the test dataset and perform predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wmu4BmG7T-J9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def imshow(img, transpose = True):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "#images, labels = dataiter.next()\n",
        "images = dataiter.next()\n",
        "labels = ['fake news', 'fake news', 'fake news', 'fake news']\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "\n",
        "outputs = net(images)\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))\n",
        "\n",
        "#imshow(torchvision.utils.make_grid(images))\n",
        "#print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "#print('GroundTruth: ', ' '.join('%5s' % classes[0] for j in range(4)))\n",
        "\n",
        "\n",
        "#outputs = net(images)\n",
        "\n",
        "#_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "#print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        " #                             for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7V1_Re1QwBO"
      },
      "outputs": [],
      "source": [
        " from sklearn.metrics import accuracy_score\n",
        " accuracy_score(labels, predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB6-7KDqWHRz"
      },
      "outputs": [],
      "source": [
        "images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDERsTrjT-J-"
      },
      "source": [
        "Let's choose a test image at index `ind` and apply some of our attribution algorithms on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzYWqwPkT-J-"
      },
      "outputs": [],
      "source": [
        "ind = 2\n",
        "\n",
        "input = images[ind].unsqueeze(0)\n",
        "input.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNv8MDrDT-J_"
      },
      "source": [
        "Sets model to eval mode for interpretation purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TIISk_MT-J_"
      },
      "outputs": [],
      "source": [
        "net.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f36ExsBLT-KA"
      },
      "source": [
        "A generic function that will be used for calling `attribute` on attribution algorithm defined in input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze0n2YDwT-KB"
      },
      "outputs": [],
      "source": [
        "def attribute_image_features(algorithm, input, **kwargs):\n",
        "    net.zero_grad()\n",
        "    tensor_attributions = algorithm.attribute(input,\n",
        "                                              target=0,\n",
        "                                              **kwargs\n",
        "                                             )\n",
        "    #labels[ind]\n",
        "    return tensor_attributions\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyaBGQvNT-KB"
      },
      "source": [
        "Computes gradients with respect to class `ind` and transposes them for visualization purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ii6Sp26T-KC"
      },
      "outputs": [],
      "source": [
        "saliency = Saliency(net)\n",
        "grads = saliency.attribute(input, target=0)\n",
        "grads = np.transpose(grads.squeeze().cpu().detach().numpy(), (1, 2, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzUSe_M8T-KC"
      },
      "source": [
        "Applies integrated gradients attribution algorithm on test image. Integrated Gradients computes the integral of the gradients of the output prediction for the class index `ind` with respect to the input image pixels. More details about integrated gradients can be found in the original paper: https://arxiv.org/abs/1703.01365"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzeqwG8vT-KD"
      },
      "outputs": [],
      "source": [
        "ig = IntegratedGradients(net)\n",
        "attr_ig, delta = attribute_image_features(ig, input, baselines=input * 0, return_convergence_delta=True)\n",
        "attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
        "print('Approximation delta: ', abs(delta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTC5M3-LT-KD"
      },
      "source": [
        "Below we demonstrate how to use integrated gradients and noise tunnel with smoothgrad square option on the test image. Noise tunnel with `smoothgrad square` option adds gaussian noise with a standard deviation of `stdevs=0.2` to the input image `nt_samples` times, computes the attributions for `nt_samples` images and returns the mean of the squared attributions across `nt_samples` images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMEUneAUT-KE"
      },
      "outputs": [],
      "source": [
        "ig = IntegratedGradients(net)\n",
        "nt = NoiseTunnel(ig)\n",
        "attr_ig_nt = attribute_image_features(nt, input, baselines=input * 0, nt_type='smoothgrad_sq',\n",
        "                                      nt_samples=100, stdevs=0.2)\n",
        "attr_ig_nt = np.transpose(attr_ig_nt.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fhpijHwT-KE"
      },
      "source": [
        "Applies DeepLift on test image. Deeplift assigns attributions to each input pixel by looking at the differences of output and its reference in terms of the differences of the input from the reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ57qTw1T-KF"
      },
      "outputs": [],
      "source": [
        "dl = DeepLift(net)\n",
        "attr_dl = attribute_image_features(dl, input, baselines=input * 0)\n",
        "attr_dl = np.transpose(attr_dl.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njBLnLX0T-KF"
      },
      "source": [
        "In the cell below we will visualize the attributions for `Saliency Maps`, `DeepLift`, `Integrated Gradients` and `Integrated Gradients with SmoothGrad`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWSXFdBOT-KF"
      },
      "outputs": [],
      "source": [
        "print('Original Image')\n",
        "print('Predicted:', classes[0], #classes[predicted[ind]], \n",
        "      ' Probability:', torch.max(F.softmax(outputs, 1)).item())\n",
        "# normalize images\n",
        "original_image = np.transpose((images[ind].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
        "\n",
        "_ = viz.visualize_image_attr(None, original_image, \n",
        "                      method=\"original_image\", title=\"Original Image\")\n",
        "\n",
        "_ = viz.visualize_image_attr(grads, original_image, method=\"blended_heat_map\", sign=\"absolute_value\",\n",
        "                          show_colorbar=True, title=\"Overlayed Gradient Magnitudes\")\n",
        "\n",
        "_ = viz.visualize_image_attr(attr_ig, original_image, method=\"blended_heat_map\",sign=\"all\",\n",
        "                          show_colorbar=True, title=\"Overlayed Integrated Gradients\")\n",
        "\n",
        "_ = viz.visualize_image_attr(attr_ig_nt, original_image, method=\"blended_heat_map\", sign=\"absolute_value\", \n",
        "                             outlier_perc=10, show_colorbar=True, \n",
        "                             title=\"Overlayed Integrated Gradients \\n with SmoothGrad Squared\")\n",
        "\n",
        "_ = viz.visualize_image_attr(attr_dl, original_image, method=\"blended_heat_map\",sign=\"all\",show_colorbar=True, \n",
        "                          title=\"Overlayed DeepLift\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Fakenews_Captum_Github.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}