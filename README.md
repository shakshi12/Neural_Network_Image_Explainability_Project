# Neural_Network_Image_Explainability_Project

Motivation
Using the two image detection datasets, the goal of this study is to investigate different explainability techniques for black-box neural network models. The first dataset is utilized for image classification, and the second dataset is used for object detection tasks. The two tasks are chosen to see how the explainability performs in these scenarios.

Introduction
In order to follow us, keep the three steps in your mind. First, decide on the dataset, second, apply deep learning models to classify the images. And third, applying various AI explainability approaches to the best-trained model. In addition, we perform explainability on the detection task utilizing the COCO dataset. Finally, we will show the explainability of image classification vs. object detection tasks.

Firstly, we shall choose two different datasets,

1. Fake News (Misinformation) Indian dataset utilizing explainabaility: Integrated Gradients, DeepLift, and Saliency Maps.
2. COCO on yolov5 with SHAP.


Proposed Methods
Deep learning based models.
